{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, ConfigParser, mediacloud, datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load mediacloud and topic_id from config file\n",
    "config = ConfigParser.ConfigParser()\n",
    "config.read('app.config')\n",
    "\n",
    "key = config.get('mediacloud','key')\n",
    "topic_id = config.get('mediacloud', 'topic_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate mediacloud api\n",
    "mc = mediacloud.api.MediaCloud(key)\n",
    "mca = mediacloud.api.AdminMediaCloud(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Background Info\n",
    "\n",
    "We're looking at the [US Presidential Election](https://topics.mediacloud.org/#/topics/1404/summary) topic in [Media Cloud](https://mediacloud.org/). That's topic ID #1404. This is a set of stories published between Apr 30, 2015 to Nov 7, 2016, queried on the names of the major presidential candidates. The topic is queried from the following media source sets:\n",
    "\n",
    "* [US Top Online News](https://sources.mediacloud.org/#/collections/9139487)\n",
    "* [US Top Digital Native News](https://sources.mediacloud.org/#/collections/9139458) \n",
    "* [US Regional Mainstream Media](https://sources.mediacloud.org/#/collections/2453107) \n",
    "\n",
    "The seed query is:\n",
    "\n",
    "> +( fiorina ( scott and walker ) ( ben and carson ) trump ( cruz and -victor ) kasich rubio (jeb and bush) clinton sanders ) AND (+publish_date:[2016-09-30T00:00:00Z TO 2016-11-08T23:59:59Z]) AND ((tags_id_media:9139487 OR tags_id_media:9139458 OR tags_id_media:2453107 OR tags_id_stories:9139487 OR tags_id_stories:9139458 OR tags_id_stories:2453107))\n",
    "\n",
    "I *think* this is the same dataset used for this CJR report, [\"Breitbart-led right-wing media ecosystem altered broader media agenda\"](https://www.cjr.org/analysis/breitbart-media-trump-harvard-study.php), but I'm not totally sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Network Structure\n",
    "\n",
    "Run this section to request a gexf file representing the unweighted, directed network of media outlets in this dataset. Nodes represent different media outlets, edges represents inlinks and outlinks between outlets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this api call takes a minute or two, but you should only need to do this once.\n",
    "\n",
    "network = mc.topicMediaMap(topic_id)\n",
    "\n",
    "with open('network.gexf', 'wb') as f:\n",
    "    f.write(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you've already generated network.gexf, run this cell to import it\n",
    "\n",
    "with open('network.gexf', 'r') as f:\n",
    "    network = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure out how to parse xml files here, maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Contagion Data\n",
    "\n",
    "Now we want to see how a term/framing/quote *propagates* through our network. To do that, we need to search the stories in our topic (#1404) for mentions of a given term/framing/quote. Let's start with the term \"alt-right\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is the query we're interested in. put the term(s) you want to search for here\n",
    "query = '( \"alt-right\" OR \"alt right\" OR \"alternative right\" )'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function fetch stories from topic, based on query\n",
    "\n",
    "def fetch_all_stories(query, topic_id):\n",
    "\n",
    "    stories_id = []\n",
    "    media_id = []\n",
    "    media_name = []\n",
    "    publish_date = []\n",
    "    media_inlink_count = []\n",
    "    outlink_count = []\n",
    "    title = []\n",
    "    url = []\n",
    "    \n",
    "    # do the first page of stories\n",
    "    stories = mc.topicStoryList(topic_id, q=query)\n",
    "    \n",
    "    # append new data to lists\n",
    "    stories_id.extend(         [s['stories_id'] for s in stories['stories']])\n",
    "    media_id.extend(           [s['media_id'] for s in stories['stories']])\n",
    "    media_name.extend(         [s['media_name'] for s in stories['stories']])\n",
    "    publish_date.extend(       [s['publish_date'] for s in stories['stories']])\n",
    "    media_inlink_count.extend( [s['media_inlink_count'] for s in stories['stories']])\n",
    "    outlink_count.extend(      [s['outlink_count'] for s in stories['stories']])\n",
    "    title.extend(              [s['title'] for s in stories['stories']])\n",
    "    url.extend(                [s['url'] for s in stories['stories']])\n",
    "    \n",
    "    nextpage_id = stories['link_ids']['next']\n",
    "    \n",
    "    # page through all the remaining stories in the topic\n",
    "    while True:\n",
    "        stories = mc.topicStoryList(topic_id, q=query, link_id = nextpage_id)\n",
    "                                    \n",
    "        # append story data\n",
    "        stories_id.extend(         [s['stories_id'] for s in stories['stories']])\n",
    "        media_id.extend(           [s['media_id'] for s in stories['stories']])\n",
    "        media_name.extend(         [s['media_name'] for s in stories['stories']])\n",
    "        publish_date.extend(       [s['publish_date'] for s in stories['stories']])\n",
    "        media_inlink_count.extend( [s['media_inlink_count'] for s in stories['stories']])\n",
    "        outlink_count.extend(      [s['outlink_count'] for s in stories['stories']])\n",
    "        title.extend(              [s['title'] for s in stories['stories']])\n",
    "        url.extend(                [s['url'] for s in stories['stories']])\n",
    "        \n",
    "        if (len(stories['stories']) < 1) or ('next' not in stories['link_ids']):\n",
    "            break\n",
    "        \n",
    "        nextpage_id = stories['link_ids']['next']\n",
    "        \n",
    "    stories = pd.DataFrame({\n",
    "                            'stories_id' : stories_id,\n",
    "                            'media_id' : media_id,\n",
    "                            'media_name' : media_name,\n",
    "                            'publish_date' : publish_date,\n",
    "                            'media_inlink_count' : media_inlink_count,\n",
    "                            'outlink_count' : outlink_count,\n",
    "                            'title' : title,\n",
    "                            'url' : url\n",
    "                            })\n",
    "        \n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stories = fetch_all_stories(query, topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write to csv\n",
    "stories.to_csv('stories_mentioning_altright.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
